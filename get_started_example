{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84764,"databundleVersionId":9695472,"sourceType":"competition"},{"sourceId":88742,"databundleVersionId":10173359,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install calplot","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-02-20T18:45:34.611997Z","iopub.execute_input":"2025-02-20T18:45:34.613190Z","iopub.status.idle":"2025-02-20T18:45:48.568384Z","shell.execute_reply.started":"2025-02-20T18:45:34.613133Z","shell.execute_reply":"2025-02-20T18:45:48.567090Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport datetime as dt\nimport seaborn as sns\nfrom colorama import Style, Fore\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, SplineTransformer, FunctionTransformer\nfrom category_encoders import OneHotEncoder, TargetEncoder\nfrom datetime import datetime\nfrom lightgbm import LGBMRegressor\nfrom scipy.optimize import differential_evolution, minimize\nfrom xgboost import XGBRegressor\nfrom sklearn.pipeline import make_pipeline, Pipeline\nimport gc\nfrom scipy.signal import periodogram\nfrom scipy.stats import kurtosis\nfrom statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\nfrom sklearn.compose import ColumnTransformer\nimport matplotlib.pyplot as plt\nfrom sklearn.base import clone, BaseEstimator, TransformerMixin\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import PredictionErrorDisplay, mean_absolute_error\nimport os\nfrom sklearn.kernel_approximation import Nystroem\nimport plotly_express as px\nimport calplot\nfrom sklearn import set_config\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nset_config(transform_output='pandas')\nplt.style.use('ggplot')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:24:26.698078Z","iopub.execute_input":"2024-11-25T14:24:26.698998Z","iopub.status.idle":"2024-11-25T14:24:26.724296Z","shell.execute_reply.started":"2024-11-25T14:24:26.69895Z","shell.execute_reply":"2024-11-25T14:24:26.722669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reading Data","metadata":{}},{"cell_type":"markdown","source":"* Load data and merge","metadata":{}},{"cell_type":"code","source":"sales_train = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv',parse_dates=['date'])\nsales_test = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_test.csv',parse_dates=['date'])\ninventory = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/inventory.csv')\ncalendar = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/calendar.csv',parse_dates=['date'])\ntest_weights = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/test_weights.csv')\nsolution = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/solution.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:26.725805Z","iopub.execute_input":"2024-11-25T14:24:26.72617Z","iopub.status.idle":"2024-11-25T14:24:32.938572Z","shell.execute_reply.started":"2024-11-25T14:24:26.726132Z","shell.execute_reply":"2024-11-25T14:24:32.937358Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sales_train = pd.merge(sales_train, inventory, how='left', on =['unique_id','warehouse'])\nsales_test = pd.merge(sales_test, inventory, how='left', on =['unique_id','warehouse'])","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:32.94111Z","iopub.execute_input":"2024-11-25T14:24:32.941514Z","iopub.status.idle":"2024-11-25T14:24:34.459405Z","shell.execute_reply.started":"2024-11-25T14:24:32.941477Z","shell.execute_reply":"2024-11-25T14:24:34.458138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sales_train = pd.merge(sales_train, calendar, how='left', on =['date','warehouse'])\nsales_test = pd.merge(sales_test, calendar, how='left', on =['date','warehouse'])","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:34.460779Z","iopub.execute_input":"2024-11-25T14:24:34.461134Z","iopub.status.idle":"2024-11-25T14:24:37.105306Z","shell.execute_reply.started":"2024-11-25T14:24:34.461098Z","shell.execute_reply":"2024-11-25T14:24:37.104067Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for df in [sales_train,sales_test]:\n    df.set_index('date',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:37.106709Z","iopub.execute_input":"2024-11-25T14:24:37.10713Z","iopub.status.idle":"2024-11-25T14:24:37.117829Z","shell.execute_reply.started":"2024-11-25T14:24:37.107091Z","shell.execute_reply":"2024-11-25T14:24:37.116427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.setdiff1d(sales_train.columns,sales_test.columns)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:37.11967Z","iopub.execute_input":"2024-11-25T14:24:37.120216Z","iopub.status.idle":"2024-11-25T14:24:37.142985Z","shell.execute_reply.started":"2024-11-25T14:24:37.12016Z","shell.execute_reply":"2024-11-25T14:24:37.141506Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sales_train.drop(['availability'], axis=1, inplace=True)\nsales_train.sort_values(['date','warehouse'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:37.144498Z","iopub.execute_input":"2024-11-25T14:24:37.145044Z","iopub.status.idle":"2024-11-25T14:24:42.248057Z","shell.execute_reply.started":"2024-11-25T14:24:37.144997Z","shell.execute_reply":"2024-11-25T14:24:42.246166Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = sales_train.reset_index().groupby(['warehouse']).agg(\n    count = ('date','size'),\n    first_date = ('date','min'),\n    last_date = ('date','max'),    \n    date_difference=('date', lambda x: x.max() - x.min()),\n    var_sales = ('sell_price_main','var'),\n    mean_price = ('sell_price_main','mean'),\n    skew_price = ('sell_price_main','skew'),    \n    max_price = ('sell_price_main','max'),\n    kurtosis_sales = ('sell_price_main',kurtosis)\n)\nresult","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:24:42.24985Z","iopub.execute_input":"2024-11-25T14:24:42.250305Z","iopub.status.idle":"2024-11-25T14:24:44.502508Z","shell.execute_reply.started":"2024-11-25T14:24:42.250263Z","shell.execute_reply":"2024-11-25T14:24:44.501302Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = sales_test.reset_index().groupby(['warehouse']).agg(\n    count = ('date','size'),\n    first_date = ('date','min'),\n    last_date = ('date','max'),    \n    date_difference=('date', lambda x: (x.max() - x.min()).days+1)\n)\nresult","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:24:44.508579Z","iopub.execute_input":"2024-11-25T14:24:44.509908Z","iopub.status.idle":"2024-11-25T14:24:44.547849Z","shell.execute_reply.started":"2024-11-25T14:24:44.509843Z","shell.execute_reply":"2024-11-25T14:24:44.5467Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del result","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:44.549062Z","iopub.execute_input":"2024-11-25T14:24:44.549402Z","iopub.status.idle":"2024-11-25T14:24:44.554692Z","shell.execute_reply.started":"2024-11-25T14:24:44.549366Z","shell.execute_reply":"2024-11-25T14:24:44.553463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Checking missing dates","metadata":{}},{"cell_type":"code","source":"u_warehouses = sales_train['warehouse'].unique()\n\nfor  w in u_warehouses:\n    missing = pd.date_range(start=sales_train.loc[sales_train.warehouse==w].index.min(),end=sales_train.loc[sales_train.warehouse==w].index.max()).difference(sales_train.loc[sales_train.warehouse==w].index)\n    if missing.size>0:\n        print(f'{Style.BRIGHT}{Fore.BLUE}**{w}**{Style.RESET_ALL}')\n        first_date = sales_train.loc[sales_train.warehouse==w].index.min().strftime(\"%Y-%m-%d\")\n        last_date  = sales_train.loc[sales_train.warehouse==w].index.max().strftime(\"%Y-%m-%d\")        \n        print(f'{Style.BRIGHT}{Fore.YELLOW} Missing Dates-> {Style.RESET_ALL}{pd.date_range(start=sales_train.loc[sales_train.warehouse==w].index.min(),end=sales_train.loc[sales_train.warehouse==w].index.max()).difference(sales_train.loc[sales_train.warehouse==w].index)}\\n')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:44.556311Z","iopub.execute_input":"2024-11-25T14:24:44.556715Z","iopub.status.idle":"2024-11-25T14:24:56.064386Z","shell.execute_reply.started":"2024-11-25T14:24:44.556677Z","shell.execute_reply":"2024-11-25T14:24:56.06286Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sales_train[sales_train.sales.isnull()]['warehouse'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:56.066047Z","iopub.execute_input":"2024-11-25T14:24:56.066529Z","iopub.status.idle":"2024-11-25T14:24:56.082699Z","shell.execute_reply.started":"2024-11-25T14:24:56.066475Z","shell.execute_reply":"2024-11-25T14:24:56.081189Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Only Munich_1 and Frankfurt_1 had days without sales. Munich_1 had 46 days and Frankfurt_1 had 6 days without sales. The other warehouses had the same number of days, 1401.\n\n* Regarding the null values ​​of these 2 warehouses, we have 2 alternatives: either we exclude them or we fill in these values ​​using some technique, such as interpolation or average values.","metadata":{}},{"cell_type":"code","source":"cat_cols = list(sales_test.select_dtypes(include='O'))\nnum_cols = list(sales_test._get_numeric_data())\ntarget = 'sales'\ninitial_features = list(sales_test.columns)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:56.084579Z","iopub.execute_input":"2024-11-25T14:24:56.084941Z","iopub.status.idle":"2024-11-25T14:24:56.0978Z","shell.execute_reply.started":"2024-11-25T14:24:56.084908Z","shell.execute_reply":"2024-11-25T14:24:56.09646Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for c in cat_cols:    \n    A = sales_train[c].fillna('None').astype(str).unique()\n    B = sales_test[c].fillna('None').astype(str).unique()\n    C = np.setdiff1d(B,A)\n    if C.size>0:\n        print(C)\n        sales_train.iloc[~sales_train[c].isin(C), c ] = 'None'\n    sales_train[c] = sales_train[c].astype('category')\n    sales_test[c] = sales_test[c].astype('category')    ","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:24:56.099213Z","iopub.execute_input":"2024-11-25T14:24:56.099605Z","iopub.status.idle":"2024-11-25T14:25:01.656156Z","shell.execute_reply.started":"2024-11-25T14:24:56.099567Z","shell.execute_reply":"2024-11-25T14:25:01.655073Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* all categories presented in the test data are also in the training data.\n* Above we converted the object types to category, due to it being more optimized when working with pandas.","metadata":{}},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"* In the graphs below we have float variables in blue, categorical ones in brown and whole ones in green.","metadata":{}},{"cell_type":"code","source":"%%time\nfig,axs= plt.subplots(11,2, figsize=(15,25),  constrained_layout=True)\nfor c, ax in zip(initial_features,axs.ravel()):\n    if sales_train[c].dtype=='float':\n        ax.hist(sales_train[c],color='blue')        \n    elif sales_train[c].dtype=='category':\n        vc = sales_train[c].value_counts() / len(sales_train)\n        ax.bar(vc.index,vc, color='brown')\n        ax.yaxis.set_major_formatter('{x:.0%}')\n        if len(vc)<=15:\n            ax.set_xticks(np.arange(len(sales_train[c].dtype.categories)), sales_train[c].dtype.categories)\n            ax.set_xticklabels(ax.get_xticklabels(),rotation=0)\n        else:\n            ax.set_xticks([])\n    elif sales_train[c].dtype=='int64':        \n        ax.hist(sales_train[c],color='green')        \n        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n    \n    ax.set_title(f'{c}', fontweight='bold')\n#axs.flat[-1].set_visible(False)\nplt.suptitle('Features', y=1.03, fontsize=25);\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:01.657402Z","iopub.execute_input":"2024-11-25T14:25:01.657747Z","iopub.status.idle":"2024-11-25T14:25:14.429803Z","shell.execute_reply.started":"2024-11-25T14:25:01.657713Z","shell.execute_reply":"2024-11-25T14:25:14.428243Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* we have high cardinality categorical variables.\n* We have many products.\n* stores stay open for the most part.\n* We have low prices, but there are high prices, but most focus on lower prices.\n* Most products are concentrated in the Bakery category\n\n\nAs they are different warehouses, it is recommended that we analyze them separately, which is what we will do next.","metadata":{}},{"cell_type":"markdown","source":"## Checking sales by warehouse","metadata":{}},{"cell_type":"markdown","source":"* Most warehouse sales are of low values, but we have outputs with high values, and each warehouse has different values. prague_2 has an output of 12000, while Munich_01 has an output of 3000.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nfor i, (combi, df) in enumerate(sales_train.groupby(['warehouse'],observed=False)):\n    ax = plt.subplot(3, 3, i+1)\n    ax.hist(df.sales, bins=20, color='blue')        \n    #ax.set_xscale('log')    \n    ax.set_title(combi)\nplt.suptitle('Histograms of sales', y=1.03)\nplt.tight_layout(h_pad=3.0)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:14.431633Z","iopub.execute_input":"2024-11-25T14:25:14.432141Z","iopub.status.idle":"2024-11-25T14:25:16.830426Z","shell.execute_reply.started":"2024-11-25T14:25:14.432082Z","shell.execute_reply":"2024-11-25T14:25:16.829171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(18,22))\nfor i, (comb, df) in enumerate(sales_train.groupby(['warehouse'],observed=False)):\n    ax = plt.subplot(7,3, i+1)        \n    sales = df.sort_values(by='date').groupby('date')['sales'].sum().reset_index()\n    trend = (sales.date - sales.iloc[0].date) // dt.timedelta(days=1)\n    trend = trend.values.reshape(-1,1)\n    model = make_pipeline(PolynomialFeatures(degree=2),\n                          LinearRegression())\n    model.fit(trend,sales.sales)\n    y_pred = pd.Series(model.predict(trend), index=sales.date)\n    \n    ax.plot(sales.date,sales.sales,label='sales', color='black',marker='o',ls='--',markersize=1)\n    y_pred.plot(ax=ax,color='red',label='trend')\n    ax.set_title(comb)\n    ax.set_xticks(ax.get_xticks())\n    ax.set_xticklabels(ax.get_xticklabels(),rotation=45)    \n    ax.legend()   \n    \n    \nplt.tight_layout()\nplt.suptitle('sales over time by warehouse',fontsize=20,y=1.02)\nplt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:25:16.832181Z","iopub.execute_input":"2024-11-25T14:25:16.832615Z","iopub.status.idle":"2024-11-25T14:25:19.836719Z","shell.execute_reply.started":"2024-11-25T14:25:16.832566Z","shell.execute_reply":"2024-11-25T14:25:19.835324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* We can observe through the trend found with Linear Regression, that not all trends are always increasing.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18,10))\nfor i, (comb, df) in enumerate(sales_train.groupby(sales_train.warehouse,observed=False)):    \n    ax = plt.subplot(4, 3, i+1, ymargin=0.5)\n    \n    resampled = df.resample('MS').sales.sum()\n    colors = ['blue'] * len(resampled)\n    ax.set_title(comb)\n    ax.set_ylim(resampled.min(), resampled.max())\n    ax.bar(range(len(resampled)), resampled)\n    ax.set_xticks(range(0, 48, 12), [f\"Jan {y}\" for y in range(2020, 2024)])        \n    ax.bar(range(len(resampled)), resampled, color=colors)\n    \nplt.suptitle('Monthly sales for 2020-2024', y=1.03)\nplt.tight_layout(h_pad=3.0)\nplt.show()    \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:19.839053Z","iopub.execute_input":"2024-11-25T14:25:19.839597Z","iopub.status.idle":"2024-11-25T14:25:22.402175Z","shell.execute_reply.started":"2024-11-25T14:25:19.839524Z","shell.execute_reply":"2024-11-25T14:25:22.40073Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(18,10))\nfor i, (comb, df) in enumerate(sales_train.groupby(sales_train.warehouse,observed=False)):    \n    ax = plt.subplot(4, 3, i+1, ymargin=0.5)\n    \n    resampled = df.resample('YS')[['sales']].mean().reset_index()\n    ax.bar(resampled.date.dt.year, resampled.sales, color='brown')\n    ax.set_title(comb)\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True)) # only integer labels\n    #ax.set_ylim(0, resampled.sales.max())   \n\n    \nplt.suptitle('Monthly sales for 2020-2024', y=1.03)\nplt.tight_layout(h_pad=3.0)\nplt.show()    \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:22.404043Z","iopub.execute_input":"2024-11-25T14:25:22.404441Z","iopub.status.idle":"2024-11-25T14:25:24.307319Z","shell.execute_reply.started":"2024-11-25T14:25:22.404402Z","shell.execute_reply":"2024-11-25T14:25:24.305897Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(18,12))\nfor i, (comb, df) in enumerate(sales_train.groupby('warehouse',observed=False)):\n    ax = plt.subplot(4,2, i+1)\n    resampled = df.sort_values(by='date').groupby(df.index.month)['sales'].sum()\n    colors = ['b'] * 5 + ['r'] * 2 + ['b'] * 5\n    ax.bar(range(1, 13), resampled, color= colors)\n    ax.set_xticks(ticks=range(1, 13), labels='JFMAMJJASOND')\n    ax.set_title(comb)\n    #ax.set_ylim(resampled.min(), resampled.max())\n        \n    \nplt.suptitle('Monthly sales', y=1.03)\nplt.tight_layout(h_pad=3.0)\nplt.show()\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:24.309247Z","iopub.execute_input":"2024-11-25T14:25:24.309656Z","iopub.status.idle":"2024-11-25T14:25:27.048814Z","shell.execute_reply.started":"2024-11-25T14:25:24.309617Z","shell.execute_reply":"2024-11-25T14:25:27.047777Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* as a whole, the months of June and July are the ones that sell the least","metadata":{}},{"cell_type":"code","source":"%%time\nyearp = sales_train.groupby(['warehouse',sales_train.index.year],observed=True)['sales'].mean().reset_index()\nplt.figure(figsize=(12,11))\nfor i,w in enumerate(u_warehouses):\n    ax = plt.subplot(len(u_warehouses),1,i+1)\n    ax.plot(yearp[yearp.warehouse==w]['date'],yearp[yearp.warehouse==w]['sales'])\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n    ax.set_title(w)\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:27.050363Z","iopub.execute_input":"2024-11-25T14:25:27.050833Z","iopub.status.idle":"2024-11-25T14:25:28.553993Z","shell.execute_reply.started":"2024-11-25T14:25:27.05078Z","shell.execute_reply":"2024-11-25T14:25:28.552707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Only munich_1 and Frankurt_1 had an increasing increase in sales per year.","metadata":{}},{"cell_type":"code","source":"mean_sales = sales_train.groupby(['shops_closed','warehouse'],observed=False)['sales'].mean().reset_index().sort_values(by='sales')\n#pivot_data = mean_sales.pivot(index='shops_closed', columns='warehouse', values='sales').fillna(0)\n#pivot_data.plot(kind='bar',stacked=True)\n_, axs = plt.subplots(1,2,figsize=(8,3), constrained_layout=True)\nax = axs.ravel()\nsns.barplot(data=mean_sales, x='shops_closed', y='sales', hue='warehouse', errorbar=None, ax=ax[0])\nax[0].legend(bbox_to_anchor=[1,1])\nsales_train.groupby(['shops_closed'])['sales'].mean().plot(kind='bar',ax=ax[1],color='green')\nax[1].bar_label(ax[1].containers[0])\nplt.suptitle('sales by shops_closed');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:28.555677Z","iopub.execute_input":"2024-11-25T14:25:28.556175Z","iopub.status.idle":"2024-11-25T14:25:29.591231Z","shell.execute_reply.started":"2024-11-25T14:25:28.556118Z","shell.execute_reply":"2024-11-25T14:25:29.589682Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* the percentage increase in relation to mean sales with a closed store is 20.25% (108798 - 904896 / 904896).\n* all warehouses sell more with stores open than closed.","metadata":{}},{"cell_type":"code","source":"tmp =sales_train.groupby(['warehouse','holiday'], observed=False).agg(\n    sales_mean = ('sales','mean'),\n    sales_min  = ('sales','min'),\n    sales_max  = ('sales','max')\n)\nax = tmp.unstack(level='warehouse')[['sales_mean']].plot(kind='bar', stacked=True)\nax.legend(bbox_to_anchor=[1,1]);\nplt.title('sales by holiday');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:29.592607Z","iopub.execute_input":"2024-11-25T14:25:29.592972Z","iopub.status.idle":"2024-11-25T14:25:30.474182Z","shell.execute_reply.started":"2024-11-25T14:25:29.592932Z","shell.execute_reply":"2024-11-25T14:25:30.472823Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:30.475851Z","iopub.execute_input":"2024-11-25T14:25:30.476299Z","iopub.status.idle":"2024-11-25T14:25:30.481621Z","shell.execute_reply.started":"2024-11-25T14:25:30.476251Z","shell.execute_reply":"2024-11-25T14:25:30.480598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"crosstab1 = pd.crosstab(index=sales_train['shops_closed'], \n                         columns=sales_train['holiday'], \n                         margins=False)\n\nstyled_crosstab1 = crosstab1.style.background_gradient(axis=0, cmap='YlOrRd')\nstyled_crosstab2 = pd.crosstab(index=[sales_train['shops_closed'], sales_train['warehouse']], \n                        columns=sales_train['holiday'], \n                        margins=False).style.background_gradient(axis=0, cmap='coolwarm')\n\ndisplay(styled_crosstab1)\n\n\n\ndisplay(styled_crosstab2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:30.482852Z","iopub.execute_input":"2024-11-25T14:25:30.483293Z","iopub.status.idle":"2024-11-25T14:25:31.252201Z","shell.execute_reply.started":"2024-11-25T14:25:30.483245Z","shell.execute_reply":"2024-11-25T14:25:31.25098Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* 3,843,953 sales when stores are open and it is not a holiday. This indicates a very high sales volume.\n72,231 sales when stores are open on public holidays. This number is significantly lower, suggesting that sales decrease around holidays.\n0 sales when stores are closed and it is not a holiday. This is to be expected as there are no sales if stores are closed.\n91,235 sales when stores are closed during holidays. This may suggest that even with stores closed, there is some type of sale or transaction (such as online sales).\n\n* For days when stores are closed (1), most sales are 0 in warehouses, except for a few, where there are still sales recorded, indicating that some stores may be operating differently or using a delivery model.","metadata":{"execution":{"iopub.status.busy":"2024-10-18T02:46:54.389446Z","iopub.execute_input":"2024-10-18T02:46:54.389868Z","iopub.status.idle":"2024-10-18T02:46:54.398827Z","shell.execute_reply.started":"2024-10-18T02:46:54.389831Z","shell.execute_reply":"2024-10-18T02:46:54.39701Z"}}},{"cell_type":"markdown","source":"# Fixing NaN values","metadata":{}},{"cell_type":"code","source":"sales_train.loc[sales_train.sales.isnull(),:].reset_index().groupby(['warehouse'],observed=False). \\\nagg(size=('warehouse','size'),\n    min_date=('date','min'),\n    max_date=('date','max'),\n    days = ('date', lambda x: x.max() - x.min()),\n    split_date=('date', lambda x: list(np.unique(np.unique(x.dt.strftime('%Y-%m-%d'))))) \n   ).dropna()","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:25:31.253527Z","iopub.execute_input":"2024-11-25T14:25:31.25389Z","iopub.status.idle":"2024-11-25T14:25:31.287084Z","shell.execute_reply.started":"2024-11-25T14:25:31.253855Z","shell.execute_reply":"2024-11-25T14:25:31.285899Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* We have sales and price records without information, this may be due to an error in data collection.","metadata":{}},{"cell_type":"code","source":"sales_train['sales'] = sales_train['sales'].fillna(0)\nsales_train['total_orders'] = sales_train['total_orders'].fillna(0)\nsales_train['sell_price_main'] = sales_train['sell_price_main'].interpolate()","metadata":{"execution":{"iopub.status.busy":"2024-11-25T14:25:31.292225Z","iopub.execute_input":"2024-11-25T14:25:31.292624Z","iopub.status.idle":"2024-11-25T14:25:31.370219Z","shell.execute_reply.started":"2024-11-25T14:25:31.292587Z","shell.execute_reply":"2024-11-25T14:25:31.368844Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Periodogram","metadata":{}},{"cell_type":"code","source":"def plot_periodogram(serie,wh,ax=None):     \n    fs = pd.Timedelta('365D') / pd.Timedelta('1D')\n    freq, spec = periodogram(serie, fs=fs,detrend='linear',scaling='spectrum')\n    \n    if ax is None:\n        fig, ax = plt.subplots(figsize=(12, 8))  \n    ax.step(freq, spec, color=\"blue\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(f\"Periodogram {wh}\")\n\nfor u in u_warehouses:\n    plot_periodogram(sales_train[sales_train.warehouse==u].groupby('date').sales.mean(),u)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:31.371778Z","iopub.execute_input":"2024-11-25T14:25:31.372289Z","iopub.status.idle":"2024-11-25T14:25:36.014109Z","shell.execute_reply.started":"2024-11-25T14:25:31.372238Z","shell.execute_reply":"2024-11-25T14:25:36.013104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Through the periodogram we can see that most warehouses have an annual seasonality and some have weekly and semi-weekly seasonality. This helps us create features so that the models can capture the seasonality of the series.","metadata":{"execution":{"iopub.status.busy":"2024-10-23T11:14:28.933147Z","iopub.execute_input":"2024-10-23T11:14:28.933805Z","iopub.status.idle":"2024-10-23T11:14:28.945651Z","shell.execute_reply.started":"2024-10-23T11:14:28.933708Z","shell.execute_reply":"2024-10-23T11:14:28.943632Z"}}},{"cell_type":"code","source":"#fig = calplot.calplot(sales_train.query('holiday==1').sales, how = \"sum\", cmap='jet')","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:36.015517Z","iopub.execute_input":"2024-11-25T14:25:36.015892Z","iopub.status.idle":"2024-11-25T14:25:36.020835Z","shell.execute_reply.started":"2024-11-25T14:25:36.015857Z","shell.execute_reply":"2024-11-25T14:25:36.019747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Metric","metadata":{}},{"cell_type":"markdown","source":"* The wMAE (Weighted Mean Absolute Error) metric is a variation of the mean absolute error that considers weights for each observation. This allows some variations to have more influence on the total error calculation, which is useful in situations where some samples are more relevant than others.","metadata":{}},{"cell_type":"code","source":"weight_map = test_weights.set_index('unique_id')['weight'].to_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:36.022246Z","iopub.execute_input":"2024-11-25T14:25:36.022605Z","iopub.status.idle":"2024-11-25T14:25:36.039288Z","shell.execute_reply.started":"2024-11-25T14:25:36.02256Z","shell.execute_reply":"2024-11-25T14:25:36.03795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sin_transformer(period):\n    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n\n\ndef cos_transformer(period):\n    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))","metadata":{"_kg_hide-input":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:36.040896Z","iopub.execute_input":"2024-11-25T14:25:36.041338Z","iopub.status.idle":"2024-11-25T14:25:36.05612Z","shell.execute_reply.started":"2024-11-25T14:25:36.0413Z","shell.execute_reply":"2024-11-25T14:25:36.054889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DropColsTransformer(BaseEstimator, TransformerMixin):\n\n    def __init__(self,cols):\n        self.cols = cols\n        \n    def fit(self,X,y=None):\n        return self\n    \n    def transform(self,X):\n        return X.drop(self.cols,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:36.057499Z","iopub.execute_input":"2024-11-25T14:25:36.0579Z","iopub.status.idle":"2024-11-25T14:25:36.070339Z","shell.execute_reply.started":"2024-11-25T14:25:36.057863Z","shell.execute_reply":"2024-11-25T14:25:36.069024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass CreateTimeFeatures(BaseEstimator, TransformerMixin):\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        df = X.copy()                \n        df['year'] = df.index.year\n        df['month'] = df.index.month\n        df['weekday'] = df.index.weekday\n        df['week'] = df.index.isocalendar().week\n        df['weekend'] = df.index.weekday // 5\n        df['semiweekly'] = np.where(df.index.weekday <3,0,1)    \n        df['year_sin'] = np.sin(df['year'] / 1 * 2 * np.pi)\n        df['year_cos'] = np.cos(df['year'] / 1 * 2 * np.pi)\n        df['month_sin'] = np.sin(df['month'] / 12 * 2 * np.pi)\n        df['month_cos'] = np.cos(df['month'] / 12 * 2 * np.pi)\n        \n\n        return df\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:36.071738Z","iopub.execute_input":"2024-11-25T14:25:36.072088Z","iopub.status.idle":"2024-11-25T14:25:36.087756Z","shell.execute_reply.started":"2024-11-25T14:25:36.072053Z","shell.execute_reply":"2024-11-25T14:25:36.086513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering\n","metadata":{}},{"cell_type":"code","source":"ctf = CreateTimeFeatures()\nsales_train = ctf.fit_transform(sales_train).copy()  \nsales_test = ctf.fit_transform(sales_test).copy() \n\nmy_index = sales_train.index\nmy_index_ts = sales_test.index\n\nagg_df = sales_train.reset_index().groupby(['name'],observed=False).agg(days_in_sale=('date','nunique'),\n                                                                   purchase_interval=('date',lambda x: (x.max() - x.min()).days)                                                               \n                                                                  ).reset_index()\nsales_train = sales_train.merge(agg_df[['name', 'days_in_sale', 'purchase_interval']], on='name', how='left')\nsales_test = sales_test.merge(agg_df[['name', 'days_in_sale', 'purchase_interval']], on='name', how='left')\nsales_train.set_index(my_index,inplace=True)\n  \nsales_train.loc[:,'date_diff'] = sales_train.reset_index().groupby('name',observed=False)['date'].diff().dt.days.fillna(0).reset_index()['date'].values\nsales_train['gap'] = sales_train['date_diff'] > 1\nsales_train['gap_group'] = sales_train.groupby(['name'],observed=False)['gap'].cumsum()\nagg_df = sales_train.groupby(['name', 'gap_group'],observed=False)['date_diff'].max().reset_index()\nagg_df = agg_df.groupby('name',observed=False)['date_diff'].max().rename('days_without_sale')\nsales_train = sales_train.merge(agg_df, on='name', how='left')\nsales_test = sales_test.merge(agg_df, on='name', how='left')\n\nsales_train.set_index(my_index,inplace=True)\nsales_test.set_index(my_index_ts,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:36.089126Z","iopub.execute_input":"2024-11-25T14:25:36.089495Z","iopub.status.idle":"2024-11-25T14:25:43.122899Z","shell.execute_reply.started":"2024-11-25T14:25:36.089458Z","shell.execute_reply":"2024-11-25T14:25:43.121579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cross Validate","metadata":{}},{"cell_type":"code","source":"oofs = {}\nscores = {}\ntest_preds = {}\nCOMPUTE_TEST = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:43.124477Z","iopub.execute_input":"2024-11-25T14:25:43.124895Z","iopub.status.idle":"2024-11-25T14:25:43.130604Z","shell.execute_reply.started":"2024-11-25T14:25:43.124857Z","shell.execute_reply":"2024-11-25T14:25:43.129282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cross_validate(estimator, features, plot_residuals=False, fit_params={}):\n    kf = TimeSeriesSplit(n_splits=5,test_size=dt.timedelta(weeks=2).days)\n    X = sales_train[features].copy()\n    y = sales_train[target]\n       \n    model = clone(estimator)\n    val_preds = np.zeros(len(X))\n    list_scores = []\n    \n    for fold, (trx_idx, val_idx) in enumerate(kf.split(X,y,groups=X['warehouse'])):        \n        X_train, y_train = X.iloc[trx_idx], y.iloc[trx_idx]\n        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]      \n                \n        model.fit(X_train.drop('unique_id',axis=1),y_train, **fit_params)\n        y_pred = model.predict(X_val.drop('unique_id',axis=1)).clip(0,None)\n        val_preds[val_idx] += y_pred\n        wmape = mean_absolute_error(y_val,y_pred,sample_weight=X_val[\"unique_id\"].map(weight_map).values)\n        list_scores.append(wmape)\n        \n        print(f' #{fold} - wmae: {wmape}')\n        if plot_residuals:\n            display = PredictionErrorDisplay.from_predictions(y_val,y_pred)            \n            plt.show()\n    if isinstance(model,Pipeline):\n        name_model = type(model[-1]).__name__\n    else:\n        name_model = type(model).__name__                              \n    \n\n    oofs[name_model] = val_preds\n    scores[name_model] = list_scores\n    print(f'wmae mean: {np.mean(list_scores)}')   \n    \n    if COMPUTE_TEST:\n        print('Computing Test prediction....')\n        model = clone(estimator)\n        model.fit(X,y)\n        \n        test_pred = model.predict(sales_test[features]).clip(0,None)\n        test_preds[name_model] = test_pred\n        print('Computing Test prediction - Ok')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:43.13172Z","iopub.execute_input":"2024-11-25T14:25:43.132089Z","iopub.status.idle":"2024-11-25T14:25:43.148845Z","shell.execute_reply.started":"2024-11-25T14:25:43.132053Z","shell.execute_reply":"2024-11-25T14:25:43.147648Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"markdown","source":"* In this first stage, the Ridge, LightGBM and XGBoost models will be used, all of which will be used with their default parameters.\n","metadata":{}},{"cell_type":"markdown","source":"## Ridge","metadata":{}},{"cell_type":"code","source":"cross_validate(make_pipeline(             \n             TargetEncoder(cols=['name',\n                                 'holiday_name',\n                                 'L2_category_name_en',\n                                 'L3_category_name_en',\n                                 'L4_category_name_en']),                                                    \n             OneHotEncoder(cols=['warehouse','L1_category_name_en']),      \n             StandardScaler(),                          \n             Ridge()),initial_features+['days_in_sale', 'purchase_interval','days_without_sale',\n                                        'year_sin','year_cos','month_sin','month_cos'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:25:43.150301Z","iopub.execute_input":"2024-11-25T14:25:43.150723Z","iopub.status.idle":"2024-11-25T14:29:22.419954Z","shell.execute_reply.started":"2024-11-25T14:25:43.150683Z","shell.execute_reply":"2024-11-25T14:29:22.418521Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## LGBM","metadata":{}},{"cell_type":"code","source":"cross_validate(make_pipeline(             \n             TargetEncoder(cols=['name',\n                                 'holiday_name',\n                                 'L2_category_name_en',\n                                 'L3_category_name_en',\n                                 'L4_category_name_en']),                                     \n             LGBMRegressor(verbosity=-1)),initial_features+['days_in_sale', 'purchase_interval','days_without_sale',\n                                                           'year_sin','year_cos','week','weekday'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:29:22.421717Z","iopub.execute_input":"2024-11-25T14:29:22.422196Z","iopub.status.idle":"2024-11-25T14:34:54.180674Z","shell.execute_reply.started":"2024-11-25T14:29:22.422141Z","shell.execute_reply":"2024-11-25T14:34:54.178908Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"cross_validate(make_pipeline(             \n             TargetEncoder(cols=['name',\n                                 'holiday_name',\n                                 'L2_category_name_en',\n                                 'L3_category_name_en',\n                                 'L4_category_name_en']),                                     \n             XGBRegressor(verbosity=0,enable_categorical=True)),\n             initial_features+['days_in_sale', 'purchase_interval'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:34:54.182999Z","iopub.execute_input":"2024-11-25T14:34:54.183509Z","iopub.status.idle":"2024-11-25T14:41:01.763745Z","shell.execute_reply.started":"2024-11-25T14:34:54.183453Z","shell.execute_reply":"2024-11-25T14:41:01.76251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scores","metadata":{}},{"cell_type":"code","source":"df_score = pd.DataFrame().from_dict(scores)\nax = df_score.mean().sort_values(ascending=False).plot(kind='barh')\nbars = ax.patches\nbars[-1].set_color('green')\nax.bar_label(ax.containers[0],label_type='center',color='white',fontweight='bold')\nplt.title('scores')\nax.set_xlabel('wmae')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:41:01.765153Z","iopub.execute_input":"2024-11-25T14:41:01.765497Z","iopub.status.idle":"2024-11-25T14:41:02.042604Z","shell.execute_reply.started":"2024-11-25T14:41:01.765462Z","shell.execute_reply":"2024-11-25T14:41:02.041287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* LGBM took this among the three models.","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"if COMPUTE_TEST:\n    solution['sales_hat'] = test_preds['LGBMRegressor'].clip(0,None)\n    solution.to_csv('submission.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T14:41:02.043896Z","iopub.execute_input":"2024-11-25T14:41:02.044248Z","iopub.status.idle":"2024-11-25T14:41:02.1733Z","shell.execute_reply.started":"2024-11-25T14:41:02.044205Z","shell.execute_reply":"2024-11-25T14:41:02.171383Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nThis notebook was a baseline, it is possible to greatly improve the result.\nTo improve we can:\n * Tune model hyperparameters\n * Ensemble models\n * Doing a deeper analysis to capture seasonality for models like Ridge makes a difference.\n * Testing other models, such as CatBoost.","metadata":{}}]}